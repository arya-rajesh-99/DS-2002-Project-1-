{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46c33ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pysparkenv/bin/python\n",
      "/opt/anaconda3/envs/pysparkenv/lib/python3.12/site-packages/pyspark\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import datetime\n",
    "import certifi\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import findspark\n",
    "findspark.init()\n",
    "print(findspark.find())\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pymongo\n",
    "import certifi\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window as W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c236050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing args for mysql and mongodb.\n",
    "# For pandas \n",
    "mysql_pandas_args = {\n",
    "    \"uid\" : \"root\",\n",
    "    \"pwd\" : \"mango4Pickle#\",\n",
    "    \"hostname\" : \"localhost\",\n",
    "    \"dbname\" : \"adventureworks\"\n",
    "}\n",
    "\n",
    "# For Spark \n",
    "mysql_spark_args = {\n",
    "    \"hostname\" : \"localhost\",\n",
    "    \"port\" : \"3306\",\n",
    "    \"dbname\" : \"adventureworks\",\n",
    "    \"conn_props\" : {\n",
    "        \"user\" : \"root\",\n",
    "        \"password\" : \"mango4Pickle#\",\n",
    "        \"driver\" : \"com.mysql.cj.jdbc.Driver\"\n",
    "    }\n",
    "} \n",
    "mongodb_args = {\n",
    "    \"user_name\" : \"arya_rajesh\",\n",
    "    \"password\" : \"mango4Pickle#\",\n",
    "    \"cluster_name\" : \"cluster0\",\n",
    "    \"cluster_subnet\" : \"wsz4m57\",\n",
    "    \"cluster_location\" : \"atlas\", # \"local\"\n",
    "    \"db_name\" : \"adventureworks\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518cae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining MongoDB get and set functions.\n",
    "\n",
    "def get_mongo_client(**args):\n",
    "    '''Validate proper input'''\n",
    "    if args[\"cluster_location\"] not in ['atlas', 'local']:\n",
    "        raise Exception(\"You must specify either 'atlas' or 'local' for the cluster_location parameter.\")\n",
    "    \n",
    "    else:\n",
    "        if args[\"cluster_location\"] == \"atlas\":\n",
    "            connect_str = f\"mongodb+srv://{args['user_name']}:{args['password']}@\"\n",
    "            connect_str += f\"{args['cluster_name']}.{args['cluster_subnet']}.mongodb.net\"\n",
    "            client = pymongo.MongoClient(connect_str, tlsCAFile=certifi.where())\n",
    "            \n",
    "        elif args[\"cluster_location\"] == \"local\":\n",
    "            client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "        \n",
    "    return client\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(mongo_client, db_name, collection, query):\n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = mongo_client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    mongo_client.close()\n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_mongo_collections(mongo_client, db_name, data_directory, json_files):\n",
    "    db = mongo_client[db_name]\n",
    "    \n",
    "    for file in json_files:\n",
    "        db.drop_collection(file)\n",
    "        json_file = os.path.join(data_directory, json_files[file])\n",
    "        with open(json_file, 'r') as openfile:\n",
    "            json_object = json.load(openfile)\n",
    "            file = db[file]\n",
    "            result = file.insert_many(json_object)\n",
    "        \n",
    "    mongo_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84adcf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining SQL get and set functions.\n",
    "def get_sql_dataframe(sql_query, **args):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{args['uid']}:{args['pwd']}@{args['hostname']}/{args['dbname']}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    dframe = pd.read_sql(text(sql_query), connection);\n",
    "    connection.close()\n",
    "    \n",
    "    return dframe\n",
    "    \n",
    "\n",
    "def set_sql_datamart_dataframe(df, table_name, pk_column, db_operation, **args):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{args['uid']}:{args['pwd']}@{args['hostname']}/{args['dbname']}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        connection.execute(text(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\"))\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()\n",
    "    \n",
    "    \n",
    "def wait_until_stream_is_ready(query, min_batches=1):\n",
    "    while len(query.recentProgress) < min_batches:\n",
    "        time.sleep(5)\n",
    "        \n",
    "    print(f\"The stream has processed {len(query.recentProgress)} batchs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82328651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark functions\n",
    "def get_file_info(path: str):\n",
    "    file_sizes = []\n",
    "    modification_times = []\n",
    "\n",
    "    '''Fetch each item in the directory, and filter out any directories.'''\n",
    "    items = os.listdir(path)\n",
    "    files = sorted([item for item in items if os.path.isfile(os.path.join(path, item))])\n",
    "\n",
    "    '''Populate lists with the Size and Last Modification DateTime for each file in the directory.'''\n",
    "    for file in files:\n",
    "        file_sizes.append(os.path.getsize(os.path.join(path, file)))\n",
    "        modification_times.append(pd.to_datetime(os.path.getmtime(os.path.join(path, file)), unit='s'))\n",
    "\n",
    "    data = list(zip(files, file_sizes, modification_times))\n",
    "    column_names = ['name','size','modification_time']\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns=column_names)\n",
    "\n",
    "\n",
    "def wait_until_stream_is_ready(query, min_batches=1):\n",
    "    while len(query.recentProgress) < min_batches:\n",
    "        time.sleep(5)\n",
    "        \n",
    "    print(f\"The stream has processed {len(query.recentProgress)} batchs\")\n",
    "\n",
    "\n",
    "def remove_directory_tree(path: str):\n",
    "    '''If it exists, remove the entire contents of a directory structure at a given 'path' parameter's location.'''\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "            return f\"Directory '{path}' has been removed successfully.\"\n",
    "        else:\n",
    "            return f\"Directory '{path}' does not exist.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "        \n",
    "\n",
    "def drop_null_columns(df, threshold):\n",
    "    '''Drop Columns having a percentage of NULL values that exceeds the given 'threshold' parameter value.'''\n",
    "    columns_with_nulls = [col for col in df.columns if df.filter(df[col].isNull()).count() / df.count() > threshold] \n",
    "    df_dropped = df.drop(*columns_with_nulls) \n",
    "    \n",
    "    return df_dropped\n",
    "    \n",
    "    \n",
    "def get_mysql_dataframe(spark_session, sql_query : str, **args):\n",
    "    '''Create a JDBC URL to the MySQL Database'''\n",
    "    jdbc_url = f\"jdbc:mysql://{args['hostname']}:{args['port']}/{args['dbname']}\"\n",
    "    \n",
    "    '''Invoke the spark.read.format(\"jdbc\") function to query the database, and fill a DataFrame.'''\n",
    "    dframe = spark_session.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"driver\", args['conn_props']['driver']) \\\n",
    "    .option(\"user\", args['conn_props']['user']) \\\n",
    "    .option(\"password\", args['conn_props']['password']) \\\n",
    "    .option(\"query\", sql_query) \\\n",
    "    .load()\n",
    "    \n",
    "    return dframe\n",
    "    \n",
    "def get_mongo_uri(**args):\n",
    "    '''Validate proper input'''\n",
    "    if args[\"cluster_location\"] not in ['atlas', 'local']:\n",
    "        raise Exception(\"You must specify either 'atlas' or 'local' for the 'cluster_location' parameter.\")\n",
    "        \n",
    "    if args['cluster_location'] == \"atlas\":\n",
    "        uri = f\"mongodb+srv://{args['user_name']}:{args['password']}@\"\n",
    "        uri += f\"{args['cluster_name']}.{args['cluster_subnet']}.mongodb.net/\"\n",
    "    else:\n",
    "        uri = \"mongodb://localhost:27017/\"\n",
    "\n",
    "    return uri\n",
    "\n",
    "def get_spark_conf_args(spark_jars : list, **args):\n",
    "    jars = \"\"\n",
    "    for jar in spark_jars:\n",
    "        jars += f\"{jar}, \"\n",
    "    \n",
    "    sparkConf_args = {\n",
    "        \"app_name\" : \"PySpark Northwind Data Lakehouse (Medallion Architecture)\",\n",
    "        \"worker_threads\" : f\"local[{int(os.cpu_count()/2)}]\",\n",
    "        \"shuffle_partitions\" : int(os.cpu_count()),\n",
    "        \"mongo_uri\" : get_mongo_uri(**args),\n",
    "        \"spark_jars\" : jars[0:-2],\n",
    "        \"database_dir\" : sql_warehouse_dir\n",
    "    }\n",
    "    \n",
    "    return sparkConf_args\n",
    "    \n",
    "\n",
    "def get_spark_conf(**args):\n",
    "    sparkConf = SparkConf().setAppName(args['app_name'])\\\n",
    "    .setMaster(args['worker_threads']) \\\n",
    "    .set('spark.driver.memory', '4g') \\\n",
    "    .set('spark.executor.memory', '2g') \\\n",
    "    .set('spark.jars', args['spark_jars']) \\\n",
    "    .set('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1') \\\n",
    "    .set('spark.mongodb.input.uri', args['mongo_uri']) \\\n",
    "    .set('spark.mongodb.output.uri', args['mongo_uri']) \\\n",
    "    .set('spark.sql.adaptive.enabled', 'false') \\\n",
    "    .set('spark.sql.debug.maxToStringFields', 35) \\\n",
    "    .set('spark.sql.shuffle.partitions', args['shuffle_partitions']) \\\n",
    "    .set('spark.sql.streaming.forceDeleteTempCheckpointLocation', 'true') \\\n",
    "    .set('spark.sql.streaming.schemaInference', 'true') \\\n",
    "    .set('spark.sql.warehouse.dir', args['database_dir']) \\\n",
    "    .set('spark.streaming.stopGracefullyOnShutdown', 'true')\n",
    "    \n",
    "    return sparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9837e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension tables: dim_products, dim_employees, and dim_vendors and dim_date\n",
    "# fact_purchaseorders fact table\n",
    "# purchase orders through MongoDB, products through csv, vendor and dim_date through mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f86b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read products csv and create df\n",
    "base_dir = os.path.join(os.getcwd(), 'data')\n",
    "batch_dir = os.path.join(base_dir, 'batch')\n",
    "stream_dir = os.path.join(base_dir, 'streaming')\n",
    "purchase_orders_stream_dir = os.path.join(stream_dir, 'purchase_orders')\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "data_file = os.path.join(batch_dir, 'adventureworks_products.csv')\n",
    "df_products = pd.read_csv(data_file, header=0, index_col=0)\n",
    "df_products.rename(columns={\"ProductID\":\"product_key\"}, inplace=True)\n",
    "df_products.head(6)\n",
    "\n",
    "\n",
    "\n",
    "dest_database = \"adventureworks_dlh\"\n",
    "sql_warehouse_dir = os.path.abspath('spark-warehouse')\n",
    "dest_database_dir = f\"{dest_database}.db\"\n",
    "database_dir = os.path.join(sql_warehouse_dir, dest_database_dir)\n",
    "\n",
    "purchase_orders_output_bronze = os.path.join(database_dir, 'fact_purchase_orders', 'bronze')\n",
    "purchase_orders_output_silver = os.path.join(database_dir, 'fact_purchase_orders', 'silver')\n",
    "purchase_orders_output_gold = os.path.join(database_dir, 'fact_purchase_orders', 'gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc18809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PurchaseOrderID  RevisionNumber  Status  EmployeeID  vendor_key  \\\n",
      "0                1               0       4         244          83   \n",
      "1                2               0       1         231          32   \n",
      "\n",
      "   product_key  OrderQty  UnitPrice  LineTotal            OrderDate  ...  \\\n",
      "0            1         4    50.2600   201.0400  2001-05-17 00:00:00  ...   \n",
      "1          360         3    45.5805   136.7415  2001-05-17 00:00:00  ...   \n",
      "\n",
      "  ShipRate             ShipDate  SubTotal   TaxAmt  Freight  TotalDue  \\\n",
      "0     2.99  2001-05-26 00:00:00  201.0400  16.0832   5.0260  222.1492   \n",
      "1     1.49  2001-05-26 00:00:00  272.1015  21.7681   6.8025  300.6721   \n",
      "\n",
      "               DueDate  ReceivedQty RejectedQty  StockedQty  \n",
      "0  2001-05-31 00:00:00          3.0         0.0         3.0  \n",
      "1  2001-05-31 00:00:00          3.0         0.0         3.0  \n",
      "\n",
      "[2 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# create purchase_orders in MongoDB and create df\n",
    "client = get_mongo_client(**mongodb_args)\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "#concatenating a string to get current working directory\n",
    "json_files = {\"purchase_orders\" : 'adventureworks_purchaseorders.json'}\n",
    "\n",
    "set_mongo_collections(client, mongodb_args[\"db_name\"], data_dir, json_files)   \n",
    "\n",
    "query = {} \n",
    "collection = \"purchase_orders\"\n",
    "df_purchaseorders = get_mongo_dataframe(client, mongodb_args[\"db_name\"], collection, query)\n",
    "df_purchaseorders.rename(columns={\"VendorID\":\"vendor_key\",\"ProductID\":\"product_key\" }, inplace=True)\n",
    "\n",
    "print(df_purchaseorders.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac635c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_key</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>Name</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>PreferredVendorStatus</th>\n",
       "      <th>ActiveFlag</th>\n",
       "      <th>AddressType</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>AddressLine2</th>\n",
       "      <th>City</th>\n",
       "      <th>StateProvinceCode</th>\n",
       "      <th>State_Province</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>INTERNAT0001</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>b'\\x01'</td>\n",
       "      <td>b'\\x01'</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>683 Larch Ct.</td>\n",
       "      <td>None</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>UT</td>\n",
       "      <td>Utah</td>\n",
       "      <td>84101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRON0002</td>\n",
       "      <td>Electronic Bike Repair &amp; Supplies</td>\n",
       "      <td>1</td>\n",
       "      <td>b'\\x01'</td>\n",
       "      <td>b'\\x01'</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>8547 Catherine Way</td>\n",
       "      <td>None</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "      <td>98403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_key AccountNumber                               Name  CreditRating  \\\n",
       "0           1  INTERNAT0001                      International             1   \n",
       "1           2  ELECTRON0002  Electronic Bike Repair & Supplies             1   \n",
       "\n",
       "  PreferredVendorStatus ActiveFlag  AddressType        AddressLine1  \\\n",
       "0               b'\\x01'    b'\\x01'  Main Office       683 Larch Ct.   \n",
       "1               b'\\x01'    b'\\x01'  Main Office  8547 Catherine Way   \n",
       "\n",
       "  AddressLine2            City StateProvinceCode State_Province PostalCode  \n",
       "0         None  Salt Lake City               UT            Utah      84101  \n",
       "1         None          Tacoma               WA      Washington      98403  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get vendors from MySQL and create df\n",
    "sql_vendor = \"SELECT * FROM adventureworks.dim_vendors_vw;\"\n",
    "df_vendor = get_sql_dataframe(sql_vendor, **mysql_pandas_args)\n",
    "df_vendor.rename(columns={\"VendorID\":\"vendor_key\"}, inplace=True)\n",
    "df_vendor.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34cc52ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['po_batch1.json', 'po_batch2.json', 'po_batch3.json']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(purchase_orders_stream_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ebd5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found minimum date and maximum date on MySQL: 2001-05-17 and 2004-09-03. Manual calculated split into three.\n",
    "sql_po_batch1 = \"SELECT * FROM adventureworks.fact_purchase_orders_vw WHERE OrderDate < '2002-01-01';\"\n",
    "\n",
    "sql_po_batch2 = \"SELECT * FROM adventureworks.fact_purchase_orders_vw WHERE OrderDate >= '2002-01-01' \\\n",
    "AND OrderDate < '2003-01-01';\"\n",
    "\n",
    "sql_po_batch3 = \"SELECT * FROM adventureworks.fact_purchase_orders_vw WHERE OrderDate >= '2003-01-01';\"\n",
    "\n",
    "# Splitting into three batches \n",
    "df_po_1 = get_sql_dataframe(sql_po_batch1, **mysql_pandas_args)\n",
    "df_po_2 = get_sql_dataframe(sql_po_batch2, **mysql_pandas_args)\n",
    "df_po_3 = get_sql_dataframe(sql_po_batch3, **mysql_pandas_args)\n",
    "\n",
    "#Exporting as JSON\n",
    "df_po_1.to_json(\n",
    "    os.path.join(purchase_orders_stream_dir, \"po_batch1.json\"),\n",
    "    orient=\"records\",\n",
    "    lines=True\n",
    ")\n",
    "\n",
    "df_po_2.to_json(\n",
    "    os.path.join(purchase_orders_stream_dir, \"po_batch2.json\"),\n",
    "    orient=\"records\",\n",
    "    lines=True\n",
    ")\n",
    "\n",
    "df_po_3.to_json(\n",
    "    os.path.join(purchase_orders_stream_dir, \"po_batch3.json\"),\n",
    "    orient=\"records\",\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2785e5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/18 11:44:28 WARN Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.25.76.59 instead (on interface en0)\n",
      "25/12/18 11:44:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/aryarajesh/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/aryarajesh/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4395f287-b62f-4b90-a653-320b82a5af21;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 60ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4395f287-b62f-4b90-a653-320b82a5af21\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/2ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/anaconda3/envs/pysparkenv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/18 11:44:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/18 11:44:28 WARN DependencyUtils: Local jar /Users/aryarajesh/Desktop/DS-2002-main/mysql-connector-j-9.1.0/mysql-connector-j-9.1.0.jar does not exist, skipping.\n",
      "25/12/18 11:44:28 INFO SparkContext: Running Spark version 3.5.7\n",
      "25/12/18 11:44:28 INFO SparkContext: OS info Mac OS X, 15.5, aarch64\n",
      "25/12/18 11:44:28 INFO SparkContext: Java version 21.0.9\n",
      "25/12/18 11:44:28 INFO ResourceUtils: ==============================================================\n",
      "25/12/18 11:44:28 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "25/12/18 11:44:28 INFO ResourceUtils: ==============================================================\n",
      "25/12/18 11:44:28 INFO SparkContext: Submitted application: PySpark Northwind Data Lakehouse (Medallion Architecture)\n",
      "25/12/18 11:44:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "25/12/18 11:44:28 INFO ResourceProfile: Limiting resource is cpu\n",
      "25/12/18 11:44:28 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "25/12/18 11:44:28 INFO SecurityManager: Changing view acls to: aryarajesh\n",
      "25/12/18 11:44:28 INFO SecurityManager: Changing modify acls to: aryarajesh\n",
      "25/12/18 11:44:28 INFO SecurityManager: Changing view acls groups to: \n",
      "25/12/18 11:44:28 INFO SecurityManager: Changing modify acls groups to: \n",
      "25/12/18 11:44:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: aryarajesh; groups with view permissions: EMPTY; users with modify permissions: aryarajesh; groups with modify permissions: EMPTY\n",
      "25/12/18 11:44:28 INFO Utils: Successfully started service 'sparkDriver' on port 53591.\n",
      "25/12/18 11:44:28 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/12/18 11:44:28 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/12/18 11:44:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "25/12/18 11:44:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "25/12/18 11:44:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/12/18 11:44:28 INFO DiskBlockManager: Created local directory at /private/var/folders/wx/fv2dc0_s6gzcmpbd2yhv94g00000gn/T/blockmgr-2e61cced-2f8e-4b65-9715-9396edc888ad\n",
      "25/12/18 11:44:28 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB\n",
      "25/12/18 11:44:28 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "25/12/18 11:44:28 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "25/12/18 11:44:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/12/18 11:44:28 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "25/12/18 11:44:28 ERROR SparkContext: Failed to add /Users/aryarajesh/Desktop/DS-2002-main/mysql-connector-j-9.1.0/mysql-connector-j-9.1.0.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /Users/aryarajesh/Desktop/DS-2002-main/mysql-connector-j-9.1.0/mysql-connector-j-9.1.0.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "25/12/18 11:44:28 INFO SparkContext: Added file file:///Users/aryarajesh/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar at file:///Users/aryarajesh/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1766076268498\n",
      "25/12/18 11:44:28 INFO Utils: Copying /Users/aryarajesh/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar to /private/var/folders/wx/fv2dc0_s6gzcmpbd2yhv94g00000gn/T/spark-5ef55e55-1d75-47d0-a799-0bbd68907e66/userFiles-98d2be91-dcfd-4ff0-bc46-8dbaf70318ea/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar\n",
      "25/12/18 11:44:28 INFO SparkContext: Added file file:///Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar at file:///Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1766076268498\n",
      "25/12/18 11:44:28 INFO Utils: Copying /Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar to /private/var/folders/wx/fv2dc0_s6gzcmpbd2yhv94g00000gn/T/spark-5ef55e55-1d75-47d0-a799-0bbd68907e66/userFiles-98d2be91-dcfd-4ff0-bc46-8dbaf70318ea/org.mongodb_mongodb-driver-sync-4.0.5.jar\n",
      "25/12/18 11:44:28 INFO SparkContext: Added file file:///Users/aryarajesh/.ivy2/jars/org.mongodb_bson-4.0.5.jar at file:///Users/aryarajesh/.ivy2/jars/org.mongodb_bson-4.0.5.jar with timestamp 1766076268498\n",
      "25/12/18 11:44:28 INFO Utils: Copying /Users/aryarajesh/.ivy2/jars/org.mongodb_bson-4.0.5.jar to /private/var/folders/wx/fv2dc0_s6gzcmpbd2yhv94g00000gn/T/spark-5ef55e55-1d75-47d0-a799-0bbd68907e66/userFiles-98d2be91-dcfd-4ff0-bc46-8dbaf70318ea/org.mongodb_bson-4.0.5.jar\n",
      "25/12/18 11:44:28 INFO SparkContext: Added file file:///Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar at file:///Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1766076268498\n",
      "25/12/18 11:44:28 INFO Utils: Copying /Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar to /private/var/folders/wx/fv2dc0_s6gzcmpbd2yhv94g00000gn/T/spark-5ef55e55-1d75-47d0-a799-0bbd68907e66/userFiles-98d2be91-dcfd-4ff0-bc46-8dbaf70318ea/org.mongodb_mongodb-driver-core-4.0.5.jar\n",
      "25/12/18 11:44:28 INFO Executor: Starting executor ID driver on host 172.25.76.59\n",
      "25/12/18 11:44:28 INFO Executor: OS info Mac OS X, 15.5, aarch64\n",
      "25/12/18 11:44:28 INFO Executor: Java version 21.0.9\n",
      "25/12/18 11:44:28 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "25/12/18 11:44:28 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@71fd6426 for default.\n",
      "25/12/18 11:44:28 INFO Executor: Fetching file:///Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1766076268498\n",
      "25/12/18 11:44:28 INFO Utils: /Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar has been previously copied to /private/var/folders/wx/fv2dc0_s6gzcmpbd2yhv94g00000gn/T/spark-5ef55e55-1d75-47d0-a799-0bbd68907e66/userFiles-98d2be91-dcfd-4ff0-bc46-8dbaf70318ea/org.mongodb_mongodb-driver-core-4.0.5.jar\n",
      "25/12/18 11:44:28 INFO Executor: Fetching file:///Users/aryarajesh/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1766076268498\n",
      "25/12/18 11:44:28 INFO Utils: /Users/aryarajesh/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar has been previously copied to /private/var/folders/wx/fv2dc0_s6gzcmpbd2yhv94g00000gn/T/spark-5ef55e55-1d75-47d0-a799-0bbd68907e66/userFiles-98d2be91-dcfd-4ff0-bc46-8dbaf70318ea/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar\n",
      "25/12/18 11:44:28 INFO Executor: Fetching file:///Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1766076268498\n",
      "25/12/18 11:44:28 INFO Utils: /Users/aryarajesh/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar has been previously copied to /private/var/folders/wx/fv2dc0_s6gzcmpbd2yhv94g00000gn/T/spark-5ef55e55-1d75-47d0-a799-0bbd68907e66/userFiles-98d2be91-dcfd-4ff0-bc46-8dbaf70318ea/org.mongodb_mongodb-driver-sync-4.0.5.jar\n",
      "25/12/18 11:44:28 INFO Executor: Fetching file:///Users/aryarajesh/.ivy2/jars/org.mongodb_bson-4.0.5.jar with timestamp 1766076268498\n",
      "25/12/18 11:44:28 INFO Utils: /Users/aryarajesh/.ivy2/jars/org.mongodb_bson-4.0.5.jar has been previously copied to /private/var/folders/wx/fv2dc0_s6gzcmpbd2yhv94g00000gn/T/spark-5ef55e55-1d75-47d0-a799-0bbd68907e66/userFiles-98d2be91-dcfd-4ff0-bc46-8dbaf70318ea/org.mongodb_bson-4.0.5.jar\n",
      "25/12/18 11:44:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53592.\n",
      "25/12/18 11:44:28 INFO NettyBlockTransferService: Server created on 172.25.76.59:53592\n",
      "25/12/18 11:44:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "25/12/18 11:44:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.25.76.59, 53592, None)\n",
      "25/12/18 11:44:28 INFO BlockManagerMasterEndpoint: Registering block manager 172.25.76.59:53592 with 2.2 GiB RAM, BlockManagerId(driver, 172.25.76.59, 53592, None)\n",
      "25/12/18 11:44:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.25.76.59, 53592, None)\n",
      "25/12/18 11:44:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.25.76.59, 53592, None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.25.76.59:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[5]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark Northwind Data Lakehouse (Medallion Architecture)</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x13a2f3aa0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating and running new spark session\n",
    "worker_threads = f\"local[{int(os.cpu_count()/2)}]\"\n",
    "\n",
    "jars = []\n",
    "mysql_spark_jar = os.path.join(os.getcwd(), \"mysql-connector-j-9.1.0\", \"mysql-connector-j-9.1.0.jar\")\n",
    "mssql_spark_jar = os.path.join(os.getcwd(), \"sqljdbc_12.8\", \"enu\", \"jars\", \"mssql-jdbc-12.8.1.jre11.jar\")\n",
    "\n",
    "jars.append(mysql_spark_jar)\n",
    "#jars.append(mssql_spark_jar)\n",
    "\n",
    "sparkConf_args = get_spark_conf_args(jars, **mongodb_args)\n",
    "\n",
    "sparkConf = get_spark_conf(**sparkConf_args)\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"OFF\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c80b85b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating new metadata base\n",
    "spark.sql(f\"DROP DATABASE IF EXISTS {dest_database} CASCADE;\")\n",
    "\n",
    "sql_create_db = f\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS {dest_database}\n",
    "    COMMENT 'DS-2002 Final Project'\n",
    "    WITH DBPROPERTIES (contains_pii = true, purpose = 'Final Project');\n",
    "\"\"\"\n",
    "spark.sql(sql_create_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe7cf8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aryarajesh/Desktop/DS-2002-main/data/batch/adventureworks_employees.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>NationalIDNumber</th>\n",
       "      <th>LoginID</th>\n",
       "      <th>ManagerID</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>MiddleName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Title</th>\n",
       "      <th>EmailAddress</th>\n",
       "      <th>EmailPromotion</th>\n",
       "      <th>Phone</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HireDate</th>\n",
       "      <th>SalariedFlag</th>\n",
       "      <th>VacationHours</th>\n",
       "      <th>SickLeaveHours</th>\n",
       "      <th>CurrentFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14417807</td>\n",
       "      <td>adventure-works\\guy1</td>\n",
       "      <td>16</td>\n",
       "      <td>Guy</td>\n",
       "      <td>R</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Production Technician - WC60</td>\n",
       "      <td>guy1@adventure-works.com</td>\n",
       "      <td>0</td>\n",
       "      <td>320-555-0195</td>\n",
       "      <td>1972-05-15</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1996-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>253022876</td>\n",
       "      <td>adventure-works\\kevin0</td>\n",
       "      <td>6</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>F</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Marketing Assistant</td>\n",
       "      <td>kevin0@adventure-works.com</td>\n",
       "      <td>2</td>\n",
       "      <td>150-555-0189</td>\n",
       "      <td>1977-06-03</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>1997-02-26</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID  NationalIDNumber                 LoginID ManagerID FirstName  \\\n",
       "0           1          14417807    adventure-works\\guy1        16       Guy   \n",
       "1           2         253022876  adventure-works\\kevin0         6     Kevin   \n",
       "\n",
       "  MiddleName LastName                         Title  \\\n",
       "0          R  Gilbert  Production Technician - WC60   \n",
       "1          F    Brown           Marketing Assistant   \n",
       "\n",
       "                 EmailAddress  EmailPromotion         Phone  BirthDate  \\\n",
       "0    guy1@adventure-works.com               0  320-555-0195 1972-05-15   \n",
       "1  kevin0@adventure-works.com               2  150-555-0189 1977-06-03   \n",
       "\n",
       "  MaritalStatus Gender   HireDate  SalariedFlag  VacationHours  \\\n",
       "0             M      M 1996-07-31             0             21   \n",
       "1             S      M 1997-02-26             0             42   \n",
       "\n",
       "   SickLeaveHours  CurrentFlag  \n",
       "0              30            1  \n",
       "1              41            1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# populating employee dimension.\n",
    "employee_csv = os.path.join(batch_dir, 'adventureworks_employees.csv')\n",
    "print(employee_csv)\n",
    "\n",
    "df_dim_employees = spark.read.format('csv').options(header='true', inferSchema='true').load(employee_csv)\n",
    "df_dim_employees.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a0429f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_key</th>\n",
       "      <th>employee_id</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>NationalIDNumber</th>\n",
       "      <th>Title</th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Guy</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>14417807</td>\n",
       "      <td>Production Technician - WC60</td>\n",
       "      <td>320-555-0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>Brown</td>\n",
       "      <td>253022876</td>\n",
       "      <td>Marketing Assistant</td>\n",
       "      <td>150-555-0189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_key  employee_id FirstName LastName  NationalIDNumber  \\\n",
       "0             1            1       Guy  Gilbert          14417807   \n",
       "1             2            2     Kevin    Brown         253022876   \n",
       "\n",
       "                          Title         Phone  \n",
       "0  Production Technician - WC60  320-555-0195  \n",
       "1           Marketing Assistant  150-555-0189  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming id. Adding the primary key column using\n",
    "# SQL windowing. Reordering columns.\n",
    "df_dim_employees = df_dim_employees.withColumnRenamed(\"EmployeeID\", \"employee_id\")\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Add Primary Key column using SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_employees.createOrReplaceTempView(\"employees\")\n",
    "sql_employees = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (ORDER BY employee_id) AS employee_key\n",
    "    FROM employees;\n",
    "\"\"\"\n",
    "df_dim_employees = spark.sql(sql_employees)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = ['employee_key', 'employee_id', 'FirstName', 'LastName', 'NationalIDNumber'\n",
    "                  , 'Title', 'Phone']\n",
    "\n",
    "df_dim_employees = df_dim_employees[ordered_columns]\n",
    "df_dim_employees.toPandas().head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67131b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fixing an error that keeps popping up for next cell:\n",
    "spark.sql(f\"DROP DATABASE IF EXISTS {dest_database} CASCADE\")\n",
    "spark.sql(f\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS {dest_database}\n",
    "COMMENT 'AdventureWorks Data Lakehouse'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77820073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in lakehouse.\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {dest_database}.dim_employees\")\n",
    "df_dim_employees.write.saveAsTable(f\"{dest_database}.dim_employees\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9603f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|        employee_key|                 int|   NULL|\n",
      "|         employee_id|                 int|   NULL|\n",
      "|           FirstName|              string|   NULL|\n",
      "|            LastName|              string|   NULL|\n",
      "|    NationalIDNumber|                 int|   NULL|\n",
      "|               Title|              string|   NULL|\n",
      "|               Phone|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|  adventureworks_dlh|       |\n",
      "|               Table|       dim_employees|       |\n",
      "|        Created Time|Thu Dec 18 11:44:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.5.7|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|             parquet|       |\n",
      "|            Location|file:/Users/aryar...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_key</th>\n",
       "      <th>employee_id</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>NationalIDNumber</th>\n",
       "      <th>Title</th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Guy</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>14417807</td>\n",
       "      <td>Production Technician - WC60</td>\n",
       "      <td>320-555-0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>Brown</td>\n",
       "      <td>253022876</td>\n",
       "      <td>Marketing Assistant</td>\n",
       "      <td>150-555-0189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_key  employee_id FirstName LastName  NationalIDNumber  \\\n",
       "0             1            1       Guy  Gilbert          14417807   \n",
       "1             2            2     Kevin    Brown         253022876   \n",
       "\n",
       "                          Title         Phone  \n",
       "0  Production Technician - WC60  320-555-0195  \n",
       "1           Marketing Assistant  150-555-0189  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Previewing employee table.\n",
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_employees;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_employees LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95a907ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+-------------+--------+-----------------+-----+----------------+------------+------------+---------+----+-------------------+---------------------+------+-----------------+-----------+-----+-----+---------------+------------------+------------+-------------+-----------+----------------+\n",
      "|_c0|ProductID|                Name|ProductNumber|MakeFlag|FinishedGoodsFlag|Color|SafetyStockLevel|ReorderPoint|StandardCost|ListPrice|Size|SizeUnitMeasureCode|WeightUnitMeasureCode|Weight|DaysToManufacture|ProductLine|Class|Style|ProductCategory|ProductSubcategory|ProductModel|SellStartDate|SellEndDate|DiscontinuedDate|\n",
      "+---+---------+--------------------+-------------+--------+-----------------+-----+----------------+------------+------------+---------+----+-------------------+---------------------+------+-----------------+-----------+-----+-----+---------------+------------------+------------+-------------+-----------+----------------+\n",
      "|  1|        1|     Adjustable Race|      AR-5381|       0|                0| NULL|            1000|         750|         0.0|      0.0|NULL|               NULL|                 NULL|  NULL|                0|       NULL| NULL| NULL|           NULL|              NULL|        NULL|  6/1/98 0:00|       NULL|            NULL|\n",
      "|  2|        2|        Bearing Ball|      BA-8327|       0|                0| NULL|            1000|         750|         0.0|      0.0|NULL|               NULL|                 NULL|  NULL|                0|       NULL| NULL| NULL|           NULL|              NULL|        NULL|  6/1/98 0:00|       NULL|            NULL|\n",
      "|  3|        3|     BB Ball Bearing|      BE-2349|       1|                0| NULL|             800|         600|         0.0|      0.0|NULL|               NULL|                 NULL|  NULL|                1|       NULL| NULL| NULL|           NULL|              NULL|        NULL|  6/1/98 0:00|       NULL|            NULL|\n",
      "|  4|        4|Headset Ball Bear...|      BE-2908|       0|                0| NULL|             800|         600|         0.0|      0.0|NULL|               NULL|                 NULL|  NULL|                0|       NULL| NULL| NULL|           NULL|              NULL|        NULL|  6/1/98 0:00|       NULL|            NULL|\n",
      "|  5|      316|               Blade|      BL-2036|       1|                0| NULL|             800|         600|         0.0|      0.0|NULL|               NULL|                 NULL|  NULL|                1|       NULL| NULL| NULL|           NULL|              NULL|        NULL|  6/1/98 0:00|       NULL|            NULL|\n",
      "+---+---------+--------------------+-------------+--------+-----------------+-----+----------------+------------+------------+---------+----+-------------------+---------------------+------+-----------------+-----------+-----+-----+---------------+------------------+------------+-------------+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_key</th>\n",
       "      <th>product_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>StandardCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Adjustable Race</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Bearing Ball</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_key  product_id             Name  StandardCost\n",
       "0            1           1  Adjustable Race           0.0\n",
       "1            2           2     Bearing Ball           0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Populating products dimension\n",
    "product_csv = os.path.join(batch_dir, \"adventureworks_products.csv\")\n",
    "\n",
    "df_dim_products = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .options(header=True, inferSchema=True)\n",
    "    .load(product_csv)\n",
    ")\n",
    "\n",
    "df_dim_products.show(5)\n",
    "#renaming key\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"ProductID\", \"product_id\")\n",
    "# Add Primary Key column using SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_products.createOrReplaceTempView(\"products\")\n",
    "sql_products = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (ORDER BY product_id) AS product_key\n",
    "    FROM products;\n",
    "\"\"\"\n",
    "df_dim_products = spark.sql(sql_products)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = ['product_key', 'product_id','Name', 'StandardCost']\n",
    "\n",
    "df_dim_products = df_dim_products[ordered_columns]\n",
    "df_dim_products.toPandas().head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24b874de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save products in lakehouse.\n",
    "#spark.sql(f\"DROP TABLE IF EXISTS {dest_database}.dim_products\")\n",
    "df_dim_products.write.saveAsTable(f\"{dest_database}.dim_products\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab0eb77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|         product_key|                 int|   NULL|\n",
      "|          product_id|                 int|   NULL|\n",
      "|                Name|              string|   NULL|\n",
      "|        StandardCost|              double|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|  adventureworks_dlh|       |\n",
      "|               Table|        dim_products|       |\n",
      "|        Created Time|Thu Dec 18 11:44:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.5.7|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|             parquet|       |\n",
      "|            Location|file:/Users/aryar...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_key</th>\n",
       "      <th>product_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>StandardCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Adjustable Race</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Bearing Ball</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_key  product_id             Name  StandardCost\n",
       "0            1           1  Adjustable Race           0.0\n",
       "1            2           2     Bearing Ball           0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Previewing products table.\n",
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_products;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_products LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d4e88ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+------------+---------------------+----------+-----------+--------------------+------------+--------------+-----------------+--------------+----------+\n",
      "|VendorID|AccountNumber|                Name|CreditRating|PreferredVendorStatus|ActiveFlag|AddressType|        AddressLine1|AddressLine2|          City|StateProvinceCode|State_Province|PostalCode|\n",
      "+--------+-------------+--------------------+------------+---------------------+----------+-----------+--------------------+------------+--------------+-----------------+--------------+----------+\n",
      "|       1| INTERNAT0001|       International|           1|                 [01]|      [01]|Main Office|       683 Larch Ct.|        NULL|Salt Lake City|              UT |          Utah|     84101|\n",
      "|       2| ELECTRON0002|Electronic Bike R...|           1|                 [01]|      [01]|Main Office|  8547 Catherine Way|        NULL|        Tacoma|              WA |    Washington|     98403|\n",
      "|       3|  PREMIER0001| Premier Sport, Inc.|           1|                 [01]|      [01]|Main Office| 7682 Fern Leaf Lane|        NULL|        Boston|              MA | Massachusetts|     02113|\n",
      "|       4|  COMFORT0001|Comfort Road Bicy...|           1|                 [01]|      [01]|Main Office|7651 Smiling Tree...|    Space 55|   Los Angeles|              CA |    California|     90012|\n",
      "|       5|  METROSP0001|Metro Sport Equip...|           1|                 [01]|      [01]|Main Office|     60 Oakgrove Rd.|        NULL|       Lebanon|              OR |        Oregon|     97355|\n",
      "+--------+-------------+--------------------+------------+---------------------+----------+-----------+--------------------+------------+--------------+-----------------+--------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_key</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>AddressType</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>City</th>\n",
       "      <th>State_Province</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>International</td>\n",
       "      <td>INTERNAT0001</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>683 Larch Ct.</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Utah</td>\n",
       "      <td>84101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Electronic Bike Repair &amp; Supplies</td>\n",
       "      <td>ELECTRON0002</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>8547 Catherine Way</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>Washington</td>\n",
       "      <td>98403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_key  vendor_id                               Name AccountNumber  \\\n",
       "0           1          1                      International  INTERNAT0001   \n",
       "1           2          2  Electronic Bike Repair & Supplies  ELECTRON0002   \n",
       "\n",
       "   AddressType        AddressLine1            City State_Province PostalCode  \n",
       "0  Main Office       683 Larch Ct.  Salt Lake City           Utah      84101  \n",
       "1  Main Office  8547 Catherine Way          Tacoma     Washington      98403  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Populating vendors dimension\n",
    "sql_vendors = \"SELECT * FROM adventureworks.dim_vendors_vw;\"\n",
    "pdf_vendors = get_sql_dataframe(sql_vendors, **mysql_pandas_args)\n",
    "\n",
    "df_dim_vendors = spark.createDataFrame(pdf_vendors)\n",
    "df_dim_vendors.show(5)\n",
    "\n",
    "#renaming key\n",
    "df_dim_vendors = df_dim_vendors.withColumnRenamed(\"VendorID\", \"vendor_id\")\n",
    "# Add Primary Key column using SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_vendors.createOrReplaceTempView(\"vendors\")\n",
    "sql_vendors = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (ORDER BY vendor_id) AS vendor_key\n",
    "    FROM vendors;\n",
    "\"\"\"\n",
    "df_dim_vendors = spark.sql(sql_vendors)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = ['vendor_key', 'vendor_id', 'Name', 'AccountNumber','AddressType', \"AddressLine1\", \"City\", \"State_Province\",'PostalCode' ]\n",
    "\n",
    "df_dim_vendors = df_dim_vendors[ordered_columns]\n",
    "df_dim_vendors.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9dad6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save vendors in lakehouse.\n",
    "#spark.sql(f\"DROP TABLE IF EXISTS {dest_database}.dim_vendors\")\n",
    "df_dim_vendors.write.saveAsTable(f\"{dest_database}.dim_vendors\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a7541a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|          vendor_key|                 int|   NULL|\n",
      "|           vendor_id|              bigint|   NULL|\n",
      "|                Name|              string|   NULL|\n",
      "|       AccountNumber|              string|   NULL|\n",
      "|         AddressType|              string|   NULL|\n",
      "|        AddressLine1|              string|   NULL|\n",
      "|                City|              string|   NULL|\n",
      "|      State_Province|              string|   NULL|\n",
      "|          PostalCode|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|  adventureworks_dlh|       |\n",
      "|               Table|         dim_vendors|       |\n",
      "|        Created Time|Thu Dec 18 11:44:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.5.7|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|             parquet|       |\n",
      "|            Location|file:/Users/aryar...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_key</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>AddressType</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>City</th>\n",
       "      <th>State_Province</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>International</td>\n",
       "      <td>INTERNAT0001</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>683 Larch Ct.</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Utah</td>\n",
       "      <td>84101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Electronic Bike Repair &amp; Supplies</td>\n",
       "      <td>ELECTRON0002</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>8547 Catherine Way</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>Washington</td>\n",
       "      <td>98403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_key  vendor_id                               Name AccountNumber  \\\n",
       "0           1          1                      International  INTERNAT0001   \n",
       "1           2          2  Electronic Bike Repair & Supplies  ELECTRON0002   \n",
       "\n",
       "   AddressType        AddressLine1            City State_Province PostalCode  \n",
       "0  Main Office       683 Larch Ct.  Salt Lake City           Utah      84101  \n",
       "1  Main Office  8547 Catherine Way          Tacoma     Washington      98403  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Previewing vendors table.\n",
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_vendors;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_vendors LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a9db9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>OrderQty</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>LineTotal</th>\n",
       "      <th>TotalDue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>2001-05-26</td>\n",
       "      <td>4</td>\n",
       "      <td>50.2600</td>\n",
       "      <td>201.0400</td>\n",
       "      <td>222.1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>32</td>\n",
       "      <td>360</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>2001-05-26</td>\n",
       "      <td>3</td>\n",
       "      <td>45.5805</td>\n",
       "      <td>136.7415</td>\n",
       "      <td>300.6721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PurchaseOrderID  EmployeeID  VendorID  ProductID  OrderDate   ShipDate  \\\n",
       "0                1         244        83          1 2001-05-17 2001-05-26   \n",
       "1                2         231        32        360 2001-05-17 2001-05-26   \n",
       "\n",
       "   OrderQty  UnitPrice  LineTotal  TotalDue  \n",
       "0         4    50.2600   201.0400  222.1492  \n",
       "1         3    45.5805   136.7415  300.6721  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating streaming purchase order data\n",
    "sql_purchase_orders = \"SELECT * FROM adventureworks.fact_purchase_orders_vw;\"\n",
    "df_purchase_orders = get_sql_dataframe(sql_purchase_orders, **mysql_pandas_args)\n",
    "\n",
    "#minimizing \n",
    "df_purchase_orders = df_purchase_orders[[\n",
    "    \"PurchaseOrderID\",\n",
    "    \"EmployeeID\",\n",
    "    \"VendorID\",\n",
    "    \"ProductID\",\n",
    "    \"OrderDate\",\n",
    "    \"ShipDate\",\n",
    "    \"OrderQty\",\n",
    "    \"UnitPrice\",\n",
    "    \"LineTotal\",\n",
    "    \"TotalDue\"\n",
    "]]\n",
    "\n",
    "df_purchase_orders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77cc3714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+-----------+\n",
      "|namespace         |tableName    |isTemporary|\n",
      "+------------------+-------------+-----------+\n",
      "|adventureworks_dlh|dim_employees|false      |\n",
      "|adventureworks_dlh|dim_products |false      |\n",
      "|adventureworks_dlh|dim_vendors  |false      |\n",
      "|                  |employees    |true       |\n",
      "|                  |products     |true       |\n",
      "|                  |vendors      |true       |\n",
      "+------------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking what dimensions are in the lakehouse\n",
    "spark.sql(f\"SHOW TABLES IN {dest_database}\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0aea97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_key</th>\n",
       "      <th>full_date</th>\n",
       "      <th>date_name</th>\n",
       "      <th>date_name_us</th>\n",
       "      <th>date_name_eu</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_name_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>weekday_weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>is_last_day_of_month</th>\n",
       "      <th>calendar_quarter</th>\n",
       "      <th>calendar_year</th>\n",
       "      <th>calendar_year_month</th>\n",
       "      <th>calendar_year_qtr</th>\n",
       "      <th>fiscal_month_of_year</th>\n",
       "      <th>fiscal_quarter</th>\n",
       "      <th>fiscal_year</th>\n",
       "      <th>fiscal_year_month</th>\n",
       "      <th>fiscal_year_qtr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000101</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000/01/01</td>\n",
       "      <td>01/01/2000</td>\n",
       "      <td>01/01/2000</td>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2000Q1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-07</td>\n",
       "      <td>2000Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000102</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>2000/01/02</td>\n",
       "      <td>01/02/2000</td>\n",
       "      <td>02/01/2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2000Q1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-07</td>\n",
       "      <td>2000Q3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_key   full_date   date_name date_name_us date_name_eu  day_of_week  \\\n",
       "0  20000101  2000-01-01  2000/01/01   01/01/2000   01/01/2000            7   \n",
       "1  20000102  2000-01-02  2000/01/02   01/02/2000   02/01/2000            1   \n",
       "\n",
       "  day_name_of_week  day_of_month  day_of_year weekday_weekend  ...  \\\n",
       "0         Saturday             1            1         Weekend  ...   \n",
       "1           Sunday             2            2         Weekend  ...   \n",
       "\n",
       "   is_last_day_of_month calendar_quarter  calendar_year calendar_year_month  \\\n",
       "0                     N                1           2000             2000-01   \n",
       "1                     N                1           2000             2000-01   \n",
       "\n",
       "   calendar_year_qtr  fiscal_month_of_year fiscal_quarter fiscal_year  \\\n",
       "0             2000Q1                     7              3        2000   \n",
       "1             2000Q1                     7              3        2000   \n",
       "\n",
       "   fiscal_year_month  fiscal_year_qtr  \n",
       "0            2000-07           2000Q3  \n",
       "1            2000-07           2000Q3  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dim_date df - edit for spark\n",
    "sql_dim_date = \"SELECT * FROM adventureworks.dim_date;\"\n",
    "df_dim_date = get_sql_dataframe(\n",
    "    sql_dim_date,\n",
    "    **mysql_pandas_args)\n",
    "df_dim_date.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33bea659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+------------+------------+-----------+----------------+------------+-----------+---------------+------------+----------+-------------+--------------------+----------------+-------------+-------------------+-----------------+--------------------+--------------+-----------+-----------------+---------------+\n",
      "|date_key| full_date| date_name|date_name_us|date_name_eu|day_of_week|day_name_of_week|day_of_month|day_of_year|weekday_weekend|week_of_year|month_name|month_of_year|is_last_day_of_month|calendar_quarter|calendar_year|calendar_year_month|calendar_year_qtr|fiscal_month_of_year|fiscal_quarter|fiscal_year|fiscal_year_month|fiscal_year_qtr|\n",
      "+--------+----------+----------+------------+------------+-----------+----------------+------------+-----------+---------------+------------+----------+-------------+--------------------+----------------+-------------+-------------------+-----------------+--------------------+--------------+-----------+-----------------+---------------+\n",
      "|20000101|2000-01-01|2000/01/01|  01/01/2000|  01/01/2000|          7|        Saturday|           1|          1|        Weekend|          52|   January|            1|                   N|               1|         2000|            2000-01|           2000Q1|                   7|             3|       2000|          2000-07|         2000Q3|\n",
      "|20000102|2000-01-02|2000/01/02|  01/02/2000|  02/01/2000|          1|          Sunday|           2|          2|        Weekend|          52|   January|            1|                   N|               1|         2000|            2000-01|           2000Q1|                   7|             3|       2000|          2000-07|         2000Q3|\n",
      "|20000103|2000-01-03|2000/01/03|  01/03/2000|  03/01/2000|          2|          Monday|           3|          3|        Weekday|           1|   January|            1|                   N|               1|         2000|            2000-01|           2000Q1|                   7|             3|       2000|          2000-07|         2000Q3|\n",
      "|20000104|2000-01-04|2000/01/04|  01/04/2000|  04/01/2000|          3|         Tuesday|           4|          4|        Weekday|           1|   January|            1|                   N|               1|         2000|            2000-01|           2000Q1|                   7|             3|       2000|          2000-07|         2000Q3|\n",
      "|20000105|2000-01-05|2000/01/05|  01/05/2000|  05/01/2000|          4|       Wednesday|           5|          5|        Weekday|           1|   January|            1|                   N|               1|         2000|            2000-01|           2000Q1|                   7|             3|       2000|          2000-07|         2000Q3|\n",
      "+--------+----------+----------+------------+------------+-----------+----------------+------------+-----------+---------------+------------+----------+-------------+--------------------+----------------+-------------+-------------------+-----------------+--------------------+--------------+-----------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create dim_date in lakehouse\n",
    "df_dim_date_spark = spark.createDataFrame(df_dim_date)\n",
    "df_dim_date_spark.show(5)\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {dest_database}.dim_date\")\n",
    "df_dim_date_spark.write.saveAsTable(\n",
    "    f\"{dest_database}.dim_date\",\n",
    "    mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33634022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+------------+------------+-----------+----------------+------------+-----------+---------------+------------+----------+-------------+--------------------+----------------+-------------+-------------------+-----------------+--------------------+--------------+-----------+-----------------+---------------+\n",
      "|date_key| full_date| date_name|date_name_us|date_name_eu|day_of_week|day_name_of_week|day_of_month|day_of_year|weekday_weekend|week_of_year|month_name|month_of_year|is_last_day_of_month|calendar_quarter|calendar_year|calendar_year_month|calendar_year_qtr|fiscal_month_of_year|fiscal_quarter|fiscal_year|fiscal_year_month|fiscal_year_qtr|\n",
      "+--------+----------+----------+------------+------------+-----------+----------------+------------+-----------+---------------+------------+----------+-------------+--------------------+----------------+-------------+-------------------+-----------------+--------------------+--------------+-----------+-----------------+---------------+\n",
      "|20081017|2008-10-17|2008/10/17|  10/17/2008|  17/10/2008|          6|          Friday|          17|        291|        Weekday|          42|   October|           10|                   N|               4|         2008|            2008-10|           2008Q4|                   4|             2|       2009|          2009-04|         2009Q2|\n",
      "|20081018|2008-10-18|2008/10/18|  10/18/2008|  18/10/2008|          7|        Saturday|          18|        292|        Weekend|          42|   October|           10|                   N|               4|         2008|            2008-10|           2008Q4|                   4|             2|       2009|          2009-04|         2009Q2|\n",
      "+--------+----------+----------+------------+------------+-----------+----------------+------------+-----------+---------------+------------+----------+-------------+--------------------+----------------+-------------+-------------------+-----------------+--------------------+--------------+-----------+-----------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table(f\"{dest_database}.dim_date\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5864611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>RevisionNumber</th>\n",
       "      <th>Status</th>\n",
       "      <th>vendor_key</th>\n",
       "      <th>product_key</th>\n",
       "      <th>OrderQty</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>LineTotal</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ShipMethod</th>\n",
       "      <th>...</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>PreferredVendorStatus</th>\n",
       "      <th>ActiveFlag</th>\n",
       "      <th>AddressType</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>AddressLine2</th>\n",
       "      <th>City</th>\n",
       "      <th>StateProvinceCode</th>\n",
       "      <th>State_Province</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>50.2600</td>\n",
       "      <td>201.0400</td>\n",
       "      <td>2001-05-17 00:00:00</td>\n",
       "      <td>OVERSEAS - DELUXE</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>b'\\x01'</td>\n",
       "      <td>b'\\x01'</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>4405 Balboa Court</td>\n",
       "      <td>None</td>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>95062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>360</td>\n",
       "      <td>3</td>\n",
       "      <td>45.5805</td>\n",
       "      <td>136.7415</td>\n",
       "      <td>2001-05-17 00:00:00</td>\n",
       "      <td>CARGO TRANSPORT 5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>b'\\x01'</td>\n",
       "      <td>b'\\x01'</td>\n",
       "      <td>Main Office</td>\n",
       "      <td>7995 Edwards Ave.</td>\n",
       "      <td>None</td>\n",
       "      <td>Lynnwood</td>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "      <td>98036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PurchaseOrderID  RevisionNumber  Status  vendor_key  product_key  OrderQty  \\\n",
       "0                1               0       4          83            1         4   \n",
       "1                2               0       1          32          360         3   \n",
       "\n",
       "   UnitPrice  LineTotal            OrderDate         ShipMethod  ...  \\\n",
       "0    50.2600   201.0400  2001-05-17 00:00:00  OVERSEAS - DELUXE  ...   \n",
       "1    45.5805   136.7415  2001-05-17 00:00:00  CARGO TRANSPORT 5  ...   \n",
       "\n",
       "   CreditRating  PreferredVendorStatus ActiveFlag  AddressType  \\\n",
       "0             1                b'\\x01'    b'\\x01'  Main Office   \n",
       "1             1                b'\\x01'    b'\\x01'  Main Office   \n",
       "\n",
       "        AddressLine1  AddressLine2        City StateProvinceCode  \\\n",
       "0  4405 Balboa Court          None  Santa Cruz               CA    \n",
       "1  7995 Edwards Ave.          None    Lynnwood               WA    \n",
       "\n",
       "   State_Province  PostalCode  \n",
       "0      California       95062  \n",
       "1      Washington       98036  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging purchaseorders and vendor dfs\n",
    "df_fact_purchaseorders = pd.merge(df_purchaseorders, df_vendor, on='vendor_key', how='inner')\n",
    "df_fact_purchaseorders.rename(columns={\"Name\":\"vendor_name\"}, inplace=True)\n",
    "df_fact_purchaseorders.drop(['EmployeeID'], axis=1, inplace=True)\n",
    "df_fact_purchaseorders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f30cd3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>RevisionNumber</th>\n",
       "      <th>Status</th>\n",
       "      <th>vendor_key</th>\n",
       "      <th>product_key</th>\n",
       "      <th>OrderQty</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>LineTotal</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ShipMethod</th>\n",
       "      <th>...</th>\n",
       "      <th>DaysToManufacture</th>\n",
       "      <th>ProductLine</th>\n",
       "      <th>Class</th>\n",
       "      <th>Style</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductSubcategory</th>\n",
       "      <th>ProductModel</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>50.2600</td>\n",
       "      <td>201.0400</td>\n",
       "      <td>2001-05-17 00:00:00</td>\n",
       "      <td>OVERSEAS - DELUXE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/98 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>360</td>\n",
       "      <td>3</td>\n",
       "      <td>45.5805</td>\n",
       "      <td>136.7415</td>\n",
       "      <td>2001-05-17 00:00:00</td>\n",
       "      <td>CARGO TRANSPORT 5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/98 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PurchaseOrderID  RevisionNumber  Status  vendor_key  product_key  OrderQty  \\\n",
       "0                1               0       4          83            1         4   \n",
       "1                2               0       1          32          360         3   \n",
       "\n",
       "   UnitPrice  LineTotal            OrderDate         ShipMethod  ...  \\\n",
       "0    50.2600   201.0400  2001-05-17 00:00:00  OVERSEAS - DELUXE  ...   \n",
       "1    45.5805   136.7415  2001-05-17 00:00:00  CARGO TRANSPORT 5  ...   \n",
       "\n",
       "   DaysToManufacture  ProductLine Class  Style  ProductCategory  \\\n",
       "0                  0          NaN   NaN    NaN              NaN   \n",
       "1                  0          NaN   NaN    NaN              NaN   \n",
       "\n",
       "   ProductSubcategory  ProductModel SellStartDate  SellEndDate  \\\n",
       "0                 NaN           NaN   6/1/98 0:00          NaN   \n",
       "1                 NaN           NaN   6/1/98 0:00          NaN   \n",
       "\n",
       "   DiscontinuedDate  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "\n",
       "[2 rows x 56 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging purchaseorders and product dfs\n",
    "df_fact_purchaseorders = pd.merge(df_fact_purchaseorders, df_products, on='product_key', how='inner')\n",
    "df_fact_purchaseorders.rename(columns={\"Name\":\"product_name\"}, inplace=True)\n",
    "df_fact_purchaseorders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a67a2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging purchaseorders and dim_date\n",
    "df_fact_purchaseorders['order_date'] = pd.to_datetime(df_fact_purchaseorders['OrderDate']).astype('datetime64[ns]').dt.date\n",
    "df_dim_order_date = df_dim_date.rename(columns={\"date_key\" : \"order_date_key\", \"full_date\" : \"order_date\"})\n",
    "df_fact_purchaseorders.drop(['OrderDate'], axis=1, inplace=True)\n",
    "df_fact_purchaseorders = pd.merge(df_fact_purchaseorders, df_dim_order_date, on='order_date', how='left')\n",
    "df_fact_purchaseorders.head(2)\n",
    "\n",
    "#Deleting Columns and Ordering Fact Table\n",
    "df_fact_purchaseorders.drop(columns=['RevisionNumber','ShipBase','CreditRating','PreferredVendorStatus','MakeFlag',\n",
    " 'FinishedGoodsFlag','Color','SafetyStockLevel','ReorderPoint','Size','SizeUnitMeasureCode','WeightUnitMeasureCode',\n",
    "                                     'Weight','DaysToManufacture','ProductLine','Class','Style' ], axis=1, inplace=True)\n",
    "\n",
    "desired_order = ['PurchaseOrderID',\n",
    "  'order_date',\n",
    " 'Status',\n",
    " 'vendor_key',       \n",
    " 'product_key', \n",
    "'order_date_key',\n",
    " 'ProductNumber',\n",
    " 'ProductCategory',\n",
    " 'ProductSubcategory',\n",
    " 'ProductModel',\n",
    " 'OrderQty',\n",
    " 'UnitPrice',\n",
    " 'LineTotal',\n",
    " 'ShipMethod',\n",
    " 'ShipRate',\n",
    " 'ShipDate',\n",
    " 'SubTotal',\n",
    " 'TaxAmt',\n",
    " 'Freight',\n",
    " 'TotalDue',\n",
    " 'DueDate',\n",
    " 'ReceivedQty',\n",
    " 'RejectedQty',\n",
    " 'StockedQty',\n",
    " 'AccountNumber',\n",
    " 'StandardCost',\n",
    " 'ListPrice',\n",
    " 'SellStartDate',\n",
    " 'SellEndDate',\n",
    " 'DiscontinuedDate',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f5bfc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>order_date</th>\n",
       "      <th>Status</th>\n",
       "      <th>vendor_key</th>\n",
       "      <th>product_key</th>\n",
       "      <th>order_date_key</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductSubcategory</th>\n",
       "      <th>ProductModel</th>\n",
       "      <th>...</th>\n",
       "      <th>DueDate</th>\n",
       "      <th>ReceivedQty</th>\n",
       "      <th>RejectedQty</th>\n",
       "      <th>StockedQty</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>ListPrice</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>20010517</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2001-05-31 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>LITWARE0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/1/98 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>360</td>\n",
       "      <td>20010517</td>\n",
       "      <td>HJ-1220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2001-05-31 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADVANCED0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/1/98 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PurchaseOrderID  order_date  Status  vendor_key  product_key  \\\n",
       "0                1  2001-05-17       4          83            1   \n",
       "1                2  2001-05-17       1          32          360   \n",
       "\n",
       "   order_date_key ProductNumber ProductCategory ProductSubcategory  \\\n",
       "0        20010517       AR-5381             NaN                NaN   \n",
       "1        20010517       HJ-1220             NaN                NaN   \n",
       "\n",
       "  ProductModel  ...              DueDate  ReceivedQty  RejectedQty StockedQty  \\\n",
       "0          NaN  ...  2001-05-31 00:00:00          3.0          0.0        3.0   \n",
       "1          NaN  ...  2001-05-31 00:00:00          3.0          0.0        3.0   \n",
       "\n",
       "   AccountNumber StandardCost  ListPrice  SellStartDate  SellEndDate  \\\n",
       "0    LITWARE0001          0.0        0.0    6/1/98 0:00          NaN   \n",
       "1   ADVANCED0001          0.0        0.0    6/1/98 0:00          NaN   \n",
       "\n",
       "   DiscontinuedDate  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Order and check columns\n",
    "df_fact_purchaseorders = df_fact_purchaseorders[desired_order]\n",
    "list(df_fact_purchaseorders)\n",
    "df_fact_purchaseorders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "386f9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_purchaseorders.insert(0, 'purchaseorder_key', range(1, len(df_fact_purchaseorders) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fe4db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new destination database (data mart)\n",
    "\n",
    "mysql_datamart_args = {\n",
    "    \"uid\" : \"root\",\n",
    "    \"pwd\" : \"mango4Pickle#\",\n",
    "    \"hostname\" : \"localhost\",\n",
    "    \"dbname\" : \"adventureworks_datamart\"\n",
    "}\n",
    "\n",
    "conn_str = f\"mysql+pymysql://{mysql_datamart_args['uid']}:{mysql_datamart_args['pwd']}@{mysql_datamart_args['hostname']}\"\n",
    "sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "connection = sqlEngine.connect()\n",
    "\n",
    "connection.execute(text(f\"DROP DATABASE IF EXISTS `{mysql_datamart_args['dbname']}`;\"))\n",
    "connection.execute(text(f\"CREATE DATABASE `{mysql_datamart_args['dbname']}`;\"))\n",
    "connection.execute(text(f\"USE {mysql_datamart_args['dbname']};\"))\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a594c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert tables into data mart\n",
    "db_operation = \"insert\"\n",
    "\n",
    "tables = [('dim_vendor', df_vendor, 'vendor_key'),\n",
    "          ('dim_products', df_products, 'product_key'),\n",
    "          ('fact_purchaseorders', df_fact_purchaseorders, 'purchaseorder_key'),\n",
    "         ('dim_date', df_dim_date, 'date_key')]\n",
    "for table_name, dataframe, primary_key in tables:\n",
    "    set_sql_datamart_dataframe(dataframe, table_name, primary_key, db_operation, **mysql_datamart_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0523704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchaseorder_key</th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>order_date</th>\n",
       "      <th>Status</th>\n",
       "      <th>vendor_key</th>\n",
       "      <th>product_key</th>\n",
       "      <th>order_date_key</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductSubcategory</th>\n",
       "      <th>...</th>\n",
       "      <th>DueDate</th>\n",
       "      <th>ReceivedQty</th>\n",
       "      <th>RejectedQty</th>\n",
       "      <th>StockedQty</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>ListPrice</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>20010517</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2001-05-31 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>LITWARE0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/1/98 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>360</td>\n",
       "      <td>20010517</td>\n",
       "      <td>HJ-1220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2001-05-31 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADVANCED0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/1/98 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchaseorder_key  PurchaseOrderID  order_date  Status  vendor_key  \\\n",
       "0                  1                1  2001-05-17       4          83   \n",
       "1                  2                2  2001-05-17       1          32   \n",
       "\n",
       "   product_key  order_date_key ProductNumber ProductCategory  \\\n",
       "0            1        20010517       AR-5381             NaN   \n",
       "1          360        20010517       HJ-1220             NaN   \n",
       "\n",
       "  ProductSubcategory  ...              DueDate  ReceivedQty  RejectedQty  \\\n",
       "0                NaN  ...  2001-05-31 00:00:00          3.0          0.0   \n",
       "1                NaN  ...  2001-05-31 00:00:00          3.0          0.0   \n",
       "\n",
       "   StockedQty AccountNumber  StandardCost ListPrice  SellStartDate  \\\n",
       "0         3.0   LITWARE0001           0.0       0.0    6/1/98 0:00   \n",
       "1         3.0  ADVANCED0001           0.0       0.0    6/1/98 0:00   \n",
       "\n",
       "   SellEndDate  DiscontinuedDate  \n",
       "0          NaN               NaN  \n",
       "1          NaN               NaN  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_purchaseorders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2531a902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_date</th>\n",
       "      <th>productnumber</th>\n",
       "      <th>accountnumber</th>\n",
       "      <th>purchaseorderid</th>\n",
       "      <th>order_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>LITWARE0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>HJ-1220</td>\n",
       "      <td>ADVANCED0001</td>\n",
       "      <td>2</td>\n",
       "      <td>2001-05-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    full_date productnumber accountnumber  purchaseorderid  order_date\n",
       "0  2001-05-17       AR-5381   LITWARE0001                1  2001-05-17\n",
       "1  2001-05-17       HJ-1220  ADVANCED0001                2  2001-05-17"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create analysis queries:\n",
    "\n",
    "sql_fact_purchaseorders = \"\"\"\n",
    "SELECT \n",
    "dt.full_date, p.productnumber, v.accountnumber, po.purchaseorderid, po.order_date\n",
    "FROM fact_purchaseorders AS po\n",
    "INNER JOIN dim_vendor AS v ON v.vendor_key = po.vendor_key\n",
    "INNER JOIN dim_products AS p ON p.product_key = po.product_key\n",
    "INNER JOIN dim_date as dt ON dt.date_key = po.order_date_key\n",
    "\"\"\"\n",
    "df_datamart_purchaseorders = get_sql_dataframe(sql_fact_purchaseorders, **mysql_datamart_args)\n",
    "df_datamart_purchaseorders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b2afd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendor Name</th>\n",
       "      <th>Product Number</th>\n",
       "      <th>Total Due Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-1213</td>\n",
       "      <td>1228.6401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-1220</td>\n",
       "      <td>1228.6401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-1420</td>\n",
       "      <td>1546.7758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-1428</td>\n",
       "      <td>1546.7758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-3410</td>\n",
       "      <td>1546.7758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-3416</td>\n",
       "      <td>1546.7758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-3816</td>\n",
       "      <td>1277.0872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-3824</td>\n",
       "      <td>1277.0872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-5161</td>\n",
       "      <td>1277.0872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>HJ-5162</td>\n",
       "      <td>1509.6709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Vendor Name Product Number  Total Due Amount\n",
       "0  Advanced Bicycles        HJ-1213         1228.6401\n",
       "1  Advanced Bicycles        HJ-1220         1228.6401\n",
       "2  Advanced Bicycles        HJ-1420         1546.7758\n",
       "3  Advanced Bicycles        HJ-1428         1546.7758\n",
       "4  Advanced Bicycles        HJ-3410         1546.7758\n",
       "5  Advanced Bicycles        HJ-3416         1546.7758\n",
       "6  Advanced Bicycles        HJ-3816         1277.0872\n",
       "7  Advanced Bicycles        HJ-3824         1277.0872\n",
       "8  Advanced Bicycles        HJ-5161         1277.0872\n",
       "9  Advanced Bicycles        HJ-5162         1509.6709"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query 1: Showing total amount due per vendor for each product\n",
    "sql_fact_purchaseorders = \"\"\"\n",
    "SELECT \n",
    "v.name AS 'Vendor Name', \n",
    "p.productnumber AS 'Product Number',\n",
    "SUM(po.totaldue) AS 'Total Due Amount'\n",
    "FROM fact_purchaseorders AS po\n",
    "INNER JOIN dim_vendor AS v ON v.vendor_key = po.vendor_key\n",
    "INNER JOIN dim_products AS p ON p.product_key = po.product_key\n",
    "INNER JOIN dim_date as dt ON dt.date_key = po.order_date_key\n",
    "GROUP BY v.vendor_key, p.productnumber\n",
    "ORDER BY v.name, p.productnumber\n",
    "\"\"\"\n",
    "df_datamart_purchaseorders = get_sql_dataframe(sql_fact_purchaseorders, **mysql_datamart_args)\n",
    "df_datamart_purchaseorders.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd8236d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendor Name</th>\n",
       "      <th>Year Quarter</th>\n",
       "      <th>Total Due Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>2001Q2</td>\n",
       "      <td>601.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>2002Q1</td>\n",
       "      <td>2475.2312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>2002Q3</td>\n",
       "      <td>1297.9716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>2002Q4</td>\n",
       "      <td>3326.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>2003Q2</td>\n",
       "      <td>521.3468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advanced Bicycles</td>\n",
       "      <td>2003Q3</td>\n",
       "      <td>10634.3880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Allenson Cycles</td>\n",
       "      <td>2001Q2</td>\n",
       "      <td>9776.2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Allenson Cycles</td>\n",
       "      <td>2002Q1</td>\n",
       "      <td>9776.2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Allenson Cycles</td>\n",
       "      <td>2002Q3</td>\n",
       "      <td>9776.2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Allenson Cycles</td>\n",
       "      <td>2002Q4</td>\n",
       "      <td>9776.2665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Vendor Name Year Quarter  Total Due Amount\n",
       "0  Advanced Bicycles       2001Q2          601.3442\n",
       "1  Advanced Bicycles       2002Q1         2475.2312\n",
       "2  Advanced Bicycles       2002Q3         1297.9716\n",
       "3  Advanced Bicycles       2002Q4         3326.2045\n",
       "4  Advanced Bicycles       2003Q2          521.3468\n",
       "5  Advanced Bicycles       2003Q3        10634.3880\n",
       "6    Allenson Cycles       2001Q2         9776.2665\n",
       "7    Allenson Cycles       2002Q1         9776.2665\n",
       "8    Allenson Cycles       2002Q3         9776.2665\n",
       "9    Allenson Cycles       2002Q4         9776.2665"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query 2: By vendor, showing quarterly total amount due:\n",
    "\n",
    "sql_fact_purchaseorders = \"\"\"\n",
    "SELECT \n",
    "v.name AS 'Vendor Name', \n",
    "dt.calendar_year_qtr AS 'Year Quarter',\n",
    "SUM(po.totaldue) AS 'Total Due Amount'\n",
    "FROM fact_purchaseorders AS po\n",
    "INNER JOIN dim_vendor AS v ON v.vendor_key = po.vendor_key\n",
    "INNER JOIN dim_date as dt ON dt.date_key = po.order_date_key\n",
    "GROUP BY v.vendor_key, dt.calendar_year_qtr\n",
    "ORDER BY v.name, dt.calendar_year_qtr\n",
    "\"\"\"\n",
    "df_datamart_purchaseorders = get_sql_dataframe(sql_fact_purchaseorders, **mysql_datamart_args)\n",
    "df_datamart_purchaseorders.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01f5fa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### BRONZE ############################\n",
    "#Creating bronze streaming:\n",
    "remove_directory_tree(purchase_orders_output_bronze)\n",
    "df_purchase_orders_bronze = (\n",
    "    spark.readStream \\\n",
    "    .option(\"schemaLocation\", purchase_orders_output_bronze) \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .json(purchase_orders_stream_dir)\n",
    ")\n",
    "\n",
    "df_purchase_orders_bronze.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89028d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing streaming data to parquet file\n",
    "purchase_orders_checkpoint_bronze = os.path.join(purchase_orders_output_bronze, '_checkpoint')\n",
    "\n",
    "purchase_orders_bronze_query = (\n",
    "    df_purchase_orders_bronze\n",
    "    # adding current timestamp and filename columns to trace.\n",
    "    .withColumn(\"receipt_time\", current_timestamp())\n",
    "    .withColumn(\"source_file\", input_file_name())\n",
    "    \n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(\"purchase_orders_bronze\")\n",
    "    .trigger(availableNow = True) \\\n",
    "    .option(\"checkpointLocation\", purchase_orders_checkpoint_bronze) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .start(purchase_orders_output_bronze)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b6b6ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 4e93ebc9-29e5-43a3-814c-e86d3c178720\n",
      "Query Name: purchase_orders_bronze\n",
      "Query Status: {'message': 'Initializing sources', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "#unit test\n",
    "print(f\"Query ID: {purchase_orders_bronze_query.id}\")\n",
    "print(f\"Query Name: {purchase_orders_bronze_query.name}\")\n",
    "print(f\"Query Status: {purchase_orders_bronze_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd6cd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_bronze_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8db6100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.part-00000-6f00b7bf-fcbc-4e96-984a-b9d5606f7e47-c000.snappy.parquet.crc',\n",
       " 'part-00000-6a32a411-14d3-4616-ae5b-05c5b07a97f6-c000.snappy.parquet',\n",
       " '_checkpoint',\n",
       " 'part-00000-1342150b-3e05-48cb-a2e8-8da69cf3ade7-c000.snappy.parquet',\n",
       " '.part-00000-1342150b-3e05-48cb-a2e8-8da69cf3ade7-c000.snappy.parquet.crc',\n",
       " '_spark_metadata',\n",
       " 'part-00000-6f00b7bf-fcbc-4e96-984a-b9d5606f7e47-c000.snappy.parquet',\n",
       " '.part-00000-6a32a411-14d3-4616-ae5b-05c5b07a97f6-c000.snappy.parquet.crc']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking json files loaded.\n",
    "os.listdir(purchase_orders_output_bronze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b92f235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase_orders_bronze_stream = (\n",
    "    spark.readStream\n",
    "        .format(\"parquet\")\n",
    "        .load(purchase_orders_output_bronze)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f0d4b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purchase_orders_bronze_stream.isStreaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e69c5798",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### SILVER ############################\n",
    "# SILVER LAYER:\n",
    "# Read streaming Bronze purchase order data, join with static dimension tables,\n",
    "# replace natural keys with surrogate keys, and write the integrated fact data\n",
    "# to the Silver layer using structured streaming (Lab 6 pattern).\n",
    "\n",
    "#loading dim_date, dim_products, dim_vendors, and dim_employees (persisted dimension tables)\n",
    "#from the Lakehouse to join with bronze facts.\n",
    "\n",
    "df_dim_date = spark.table(f\"{dest_database}.dim_date\")\n",
    "df_dim_products = spark.table(f\"{dest_database}.dim_products\")\n",
    "df_dim_vendors = spark.table(f\"{dest_database}.dim_vendors\")\n",
    "df_dim_employees = spark.table(f\"{dest_database}.dim_employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aef6b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing role-playing dimension primary and business keys; order dates are different formats so cannot use alias\n",
    "df_dim_order_date = df_dim_date.select(\n",
    "    col(\"date_key\").cast(\"long\").alias(\"order_date_key\"),\n",
    "    col(\"month_of_year\").cast(\"int\").alias(\"month_of_year\"),\n",
    "    col(\"month_name\").alias(\"month_name\")\n",
    ")\n",
    "\n",
    "df_dim_ship_date = df_dim_date.select(\n",
    "    col(\"date_key\").alias(\"shipped_date_key\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0423c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading bronze and joining, don't need to cast since already int\n",
    "#time format must be changed for dim_date to be used in streaming so using pyspark functions\n",
    "from pyspark.sql.functions import from_unixtime, date_format\n",
    "\n",
    "df_purchase_orders_silver = (\n",
    "    df_purchase_orders_bronze_stream\n",
    "       .join(\n",
    "            df_dim_order_date,\n",
    "            date_format(\n",
    "                from_unixtime(col(\"OrderDate\") / 1000),\n",
    "                \"yyyyMMdd\").cast(\"long\") == col(\"order_date_key\"),\n",
    "            \"left\"\n",
    "\n",
    "        )\n",
    "        .join(\n",
    "            df_dim_products,\n",
    "            col(\"ProductID\") == df_dim_products.product_id,\n",
    "            \"left\"\n",
    "        )\n",
    "        .join(\n",
    "            df_dim_vendors,\n",
    "            col(\"VendorID\") == df_dim_vendors.vendor_id,\n",
    "            \"left\"\n",
    "        )\n",
    "        .join(\n",
    "            df_dim_employees,\n",
    "            col(\"EmployeeID\") == df_dim_employees.employee_id,\n",
    "            \"left\"\n",
    "        )\n",
    "        .select(\n",
    "            col(\"PurchaseOrderID\").cast(\"long\"),\n",
    "            col(\"order_date_key\").cast(\"long\"),\n",
    "            df_dim_order_date.month_of_year.cast(\"int\"),\n",
    "            df_dim_order_date.month_name,\n",
    "            df_dim_products.product_key.cast(\"int\"),\n",
    "            df_dim_vendors.vendor_key.cast(\"int\"),\n",
    "            df_dim_employees.employee_key.cast(\"int\"),\n",
    "            col(\"OrderQty\"),\n",
    "            col(\"UnitPrice\"),\n",
    "            col(\"LineTotal\"),\n",
    "            col(\"TotalDue\")\n",
    "        )\n",
    ")\n",
    "\n",
    "#organizing columns\n",
    "df_purchase_orders_silver = df_purchase_orders_silver.selectExpr(\n",
    "    \"PurchaseOrderID\",\n",
    "    \"order_date_key\",\n",
    "    \"month_of_year\",\n",
    "    \"month_name\",\n",
    "    \"product_key\",\n",
    "    \"vendor_key\",\n",
    "    \"employee_key\",\n",
    "    \"OrderQty\",\n",
    "    \"UnitPrice\",\n",
    "    \"LineTotal\",\n",
    "    \"TotalDue\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bef3055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PurchaseOrderID: long (nullable = true)\n",
      " |-- order_date_key: long (nullable = true)\n",
      " |-- month_of_year: integer (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- product_key: integer (nullable = true)\n",
      " |-- vendor_key: integer (nullable = true)\n",
      " |-- employee_key: integer (nullable = true)\n",
      " |-- OrderQty: long (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- LineTotal: double (nullable = true)\n",
      " |-- TotalDue: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_purchase_orders_silver.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be4d1206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purchase_orders_silver.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed69b83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+\n",
      "|PurchaseOrderID|    OrderDate|\n",
      "+---------------+-------------+\n",
      "|              1| 990057600000|\n",
      "|              9|1010966400000|\n",
      "|            281|1047427200000|\n",
      "+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(purchase_orders_output_bronze) \\\n",
    "    .select(\"PurchaseOrderID\", \"OrderDate\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fad960dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the transformed streaming data to the data lakehouse\n",
    "purchase_orders_checkpoint_silver = os.path.join(\n",
    "    purchase_orders_output_silver, \"_checkpoint\"\n",
    ")\n",
    "purchase_orders_silver_query = (\n",
    "    df_purchase_orders_silver\n",
    "        .writeStream\n",
    "        .format(\"parquet\")\n",
    "        .outputMode(\"append\")\n",
    "        .queryName(\"purchase_orders_silver\")\n",
    "        .trigger(availableNow=True)\n",
    "        .option(\"checkpointLocation\", purchase_orders_checkpoint_silver)\n",
    "        .option(\"compression\", \"snappy\")\n",
    "        .start(purchase_orders_output_silver)\n",
    ")\n",
    "\n",
    "purchase_orders_silver_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d05ee801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+-------------+----------+\n",
      "|PurchaseOrderID|order_date_key|month_of_year|month_name|\n",
      "+---------------+--------------+-------------+----------+\n",
      "|              9|      20020113|            1|   January|\n",
      "|            281|      20030311|            3|     March|\n",
      "|              1|      20010516|            5|       May|\n",
      "+---------------+--------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(purchase_orders_output_silver) \\\n",
    "    .select(\"PurchaseOrderID\", \"order_date_key\", \"month_of_year\", \"month_name\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "30e4f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stream has processed 1 batchs\n"
     ]
    }
   ],
   "source": [
    "#stream process check\n",
    "wait_until_stream_is_ready(purchase_orders_silver_query, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db932bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase_orders_silver_stream = (\n",
    "    spark.readStream\n",
    "        .format(\"parquet\")\n",
    "        .load(purchase_orders_output_silver)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "477b0cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purchase_orders_silver_stream.isStreaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "957f9e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 037ac684-b5d7-4ef9-a737-bd7ad39e3d3a\n",
      "Query Name: purchase_orders_silver\n",
      "Query Status: {'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "#unit test to implement query monitoring\n",
    "print(f\"Query ID: {purchase_orders_silver_query.id}\")\n",
    "print(f\"Query Name: {purchase_orders_silver_query.name}\")\n",
    "print(f\"Query Status: {purchase_orders_silver_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f38db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### GOLD ############################\n",
    "# This section mirrors Lab 6, Section 6 Gold. Like in Lab 6, the Silver-level fact data is aggregated, \n",
    "#joint to dimension tables, and compute monthly product metrics.\n",
    "# For this project, AdventureWorks does not include Product Category in the dim_products table, \n",
    "# so Product Name is used as the dimension.\n",
    "\n",
    "#Define query to create business report.\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df_purchase_orders_by_product_gold = (\n",
    "    df_purchase_orders_silver_stream\n",
    "        .groupBy(\"month_of_year\", \"month_name\", \"product_key\")\n",
    "        .agg(count(\"*\").alias(\"product_count\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2782305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the streaming data to a parquet file in \"complete\" mode\n",
    "orders_gold_query = (\n",
    "    df_purchase_orders_by_product_gold.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .queryName(\"df_fact_purchase_orders_by_product\")\n",
    "    .trigger(availableNow=True)\n",
    "    .start()\n",
    ")\n",
    "\n",
    "orders_gold_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8705dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stream has processed 1 batchs\n"
     ]
    }
   ],
   "source": [
    "wait_until_stream_is_ready(orders_gold_query, 1)\n",
    "orders_gold_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f25f5d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----------+-------------+\n",
      "|month_of_year|month_name|product_key|product_count|\n",
      "+-------------+----------+-----------+-------------+\n",
      "|            3|     March|        141|            1|\n",
      "|            5|       May|          1|            1|\n",
      "|            1|   January|        105|            1|\n",
      "+-------------+----------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM df_fact_purchase_orders_by_product\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "261c377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the final selection\n",
    "df_fact_purchase_orders_by_product_full = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        month_of_year,\n",
    "        month_name,\n",
    "        product_key,\n",
    "        product_count\n",
    "    FROM df_fact_purchase_orders_by_product\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "440cc162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Product</th>\n",
       "      <th>Product_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>March</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  Product  Product_Count\n",
       "0  January      105              1\n",
       "1    March      141              1\n",
       "2      May        1              1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load final table and display results in table\n",
    "df_fact_purchase_orders_by_product_full.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{dest_database}.fact_purchase_orders_by_product\")\n",
    "\n",
    "final_df_pd = spark.sql(f\" SELECT month_name AS Month, \\\n",
    "        product_key AS Product, \\\n",
    "        product_count AS Product_Count \\\n",
    "    FROM {dest_database}.fact_purchase_orders_by_product \\\n",
    "    ORDER BY month_of_year, Product_Count DESC \").toPandas()\n",
    "\n",
    "final_df_pd\n",
    "\n",
    "# This final Gold fact table displays the number of purchase-order line items\n",
    "# per product, by month, enabling business analysis\n",
    "# of purchasing activity over time (by showing how many times each product appears \n",
    "# in purchase orders for each month.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90efded8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Employee</th>\n",
       "      <th>Orders</th>\n",
       "      <th>Total_Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>74</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>767.0528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>March</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "      <td>158.0608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May</td>\n",
       "      <td>83</td>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "      <td>222.1492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  Vendor  Employee  Orders  Total_Spend\n",
       "0  January      74       261       1     767.0528\n",
       "1    March       1       244       1     158.0608\n",
       "2      May      83       244       1     222.1492"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##additional query using more dimensions:\n",
    "#query from silver\n",
    "df_purchase_orders_silver_batch = spark.read.parquet(purchase_orders_output_silver)\n",
    "\n",
    "#joining dimensions to aggregate\n",
    "df_fact_purchase_orders_by_vendor_employee = (\n",
    "    df_purchase_orders_silver_batch\n",
    "        .join(df_dim_vendors, \"vendor_key\")\n",
    "        .join(df_dim_employees, \"employee_key\")\n",
    "        .groupBy(\n",
    "            \"month_name\",\n",
    "            \"month_of_year\",\n",
    "            \"vendor_key\",\n",
    "            \"employee_key\"\n",
    "        )\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"order_count\"),\n",
    "            sum(\"TotalDue\").alias(\"total_spend\")\n",
    "        )\n",
    ")\n",
    "#vendors table\n",
    "df_fact_purchase_orders_by_vendor_employee.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{dest_database}.fact_purchase_orders_by_vendor_employee\")\n",
    "\n",
    "#vendors query\n",
    "vendor_employee_report = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        month_name AS Month,\n",
    "        vendor_key AS Vendor,\n",
    "        employee_key AS Employee,\n",
    "        order_count AS Orders,\n",
    "        total_spend AS Total_Spend\n",
    "    FROM {dest_database}.fact_purchase_orders_by_vendor_employee\n",
    "    ORDER BY month_of_year, Total_Spend DESC\n",
    "\"\"\").toPandas()\n",
    "\n",
    "vendor_employee_report\n",
    "\n",
    "# This report summarizes purchase-order activity by vendor and employee,\n",
    "# by each month, including number of orders and total spending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "86ed12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c5598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pysparkenv)",
   "language": "python",
   "name": "pysparkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
